{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, BatchNormalization,MaxPooling2D, GlobalAveragePooling2D, Resizing, Rescaling\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import Model\n",
    "from keras.models import load_model\n",
    "import tensorflow.keras.utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = pd.read_csv('../Data/Group_by.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Location</th>\n",
       "      <th>Province</th>\n",
       "      <th>Railway</th>\n",
       "      <th>Protection</th>\n",
       "      <th>Trains Daily</th>\n",
       "      <th>Count</th>\n",
       "      <th>Train Max Speed (mph)</th>\n",
       "      <th>Road Max Speed (km/h)</th>\n",
       "      <th>Vehicles Daily</th>\n",
       "      <th>Protection_en</th>\n",
       "      <th>Province_en</th>\n",
       "      <th>Railway_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10997</td>\n",
       "      <td>SK</td>\n",
       "      <td>LCR</td>\n",
       "      <td>Passive</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11138</td>\n",
       "      <td>SK</td>\n",
       "      <td>CN</td>\n",
       "      <td>Passive</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11167</td>\n",
       "      <td>SK</td>\n",
       "      <td>STRCO</td>\n",
       "      <td>Passive</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11176</td>\n",
       "      <td>SK</td>\n",
       "      <td>GWR</td>\n",
       "      <td>Passive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11178</td>\n",
       "      <td>SK</td>\n",
       "      <td>GWR</td>\n",
       "      <td>Passive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15369</th>\n",
       "      <td>16565</td>\n",
       "      <td>private access to maintenance bldg</td>\n",
       "      <td>BC</td>\n",
       "      <td>CN</td>\n",
       "      <td>Passive</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15370</th>\n",
       "      <td>16570</td>\n",
       "      <td>unknown</td>\n",
       "      <td>BC</td>\n",
       "      <td>BNSFRC</td>\n",
       "      <td>Passive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15371</th>\n",
       "      <td>16571</td>\n",
       "      <td>unknown</td>\n",
       "      <td>BC</td>\n",
       "      <td>CN</td>\n",
       "      <td>Passive</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15372</th>\n",
       "      <td>16572</td>\n",
       "      <td>unnamed farm road</td>\n",
       "      <td>BC</td>\n",
       "      <td>CN</td>\n",
       "      <td>Passive</td>\n",
       "      <td>39.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15373</th>\n",
       "      <td>16573</td>\n",
       "      <td>Éntrée Principale À Alcan</td>\n",
       "      <td>QC</td>\n",
       "      <td>CN</td>\n",
       "      <td>Passive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15374 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            Location Province Railway  \\\n",
       "0               0                               10997       SK     LCR   \n",
       "1               1                               11138       SK      CN   \n",
       "2               2                               11167       SK   STRCO   \n",
       "3               3                               11176       SK     GWR   \n",
       "4               4                               11178       SK     GWR   \n",
       "...           ...                                 ...      ...     ...   \n",
       "15369       16565  private access to maintenance bldg       BC      CN   \n",
       "15370       16570                             unknown       BC  BNSFRC   \n",
       "15371       16571                             unknown       BC      CN   \n",
       "15372       16572                   unnamed farm road       BC      CN   \n",
       "15373       16573           Éntrée Principale À Alcan       QC      CN   \n",
       "\n",
       "      Protection  Trains Daily  Count  Train Max Speed (mph)  \\\n",
       "0        Passive          0.01    0.0                   10.0   \n",
       "1        Passive          4.06    0.0                   30.0   \n",
       "2        Passive          2.00    0.0                   10.0   \n",
       "3        Passive          1.00    0.0                   35.0   \n",
       "4        Passive          1.00    0.0                   35.0   \n",
       "...          ...           ...    ...                    ...   \n",
       "15369    Passive          3.00    0.0                   20.0   \n",
       "15370    Passive          1.00    0.0                   10.0   \n",
       "15371    Passive          6.43    0.0                   40.0   \n",
       "15372    Passive         39.86    0.0                   60.0   \n",
       "15373    Passive          1.00    0.0                   10.0   \n",
       "\n",
       "       Road Max Speed (km/h)  Vehicles Daily  Protection_en  Province_en  \\\n",
       "0                       50.0             2.0              3            9   \n",
       "1                       50.0            50.0              3            9   \n",
       "2                       80.0             2.0              3            9   \n",
       "3                       50.0            10.0              3            9   \n",
       "4                       50.0            25.0              3            9   \n",
       "...                      ...             ...            ...          ...   \n",
       "15369                   10.0            25.0              3            1   \n",
       "15370                    0.0             1.0              3            1   \n",
       "15371                   25.0            10.0              3            1   \n",
       "15372                   15.0             5.0              3            1   \n",
       "15373                   25.0            10.0              3            8   \n",
       "\n",
       "       Railway_en  \n",
       "0              43  \n",
       "1              18  \n",
       "2              65  \n",
       "3              33  \n",
       "4              33  \n",
       "...           ...  \n",
       "15369          18  \n",
       "15370           8  \n",
       "15371          18  \n",
       "15372          18  \n",
       "15373          18  \n",
       "\n",
       "[15374 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15374, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = grp['Count'].astype('float32')\n",
    "X = grp[[\n",
    "                            \n",
    "                            'Trains Daily',\n",
    "                            'Vehicles Daily',\n",
    "                            'Train Max Speed (mph)',\n",
    "                            'Road Max Speed (km/h)',\n",
    "                            # 'ApproxTrainSpeed_MPH',\n",
    "                            # 'NumCars',\n",
    "                            # 'TrainLength_Feet'\n",
    "                            ]]\n",
    "\n",
    "\n",
    "\n",
    "# poisson_training_results = sm.GLM(y1, X, family=sm.families.NegativeBinomial()).fit()\n",
    "# print(poisson_training_results.summary())\n",
    "\n",
    "# X = pd.DataFrame(MinMaxScaler().fit_transform(X),columns = X.columns)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Count   No. Observations:                15374\n",
      "Model:                            GLM   Df Residuals:                    15356\n",
      "Model Family:                 Poisson   Df Model:                           17\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -8409.4\n",
      "Date:                Sun, 09 Apr 2023   Deviance:                       12059.\n",
      "Time:                        15:05:52   Pearson chi2:                 2.63e+04\n",
      "No. Iterations:                    21   Pseudo R-squ. (CS):             0.1247\n",
      "Covariance Type:                  HC2                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    -4.3033   2.27e+05   -1.9e-05      1.000   -4.45e+05    4.45e+05\n",
      "Trains Daily              0.0058      0.002      2.977      0.003       0.002       0.010\n",
      "Vehicles Daily         5.137e-05   3.57e-06     14.401      0.000    4.44e-05    5.84e-05\n",
      "Train Max Speed (mph)     0.0161      0.002      8.032      0.000       0.012       0.020\n",
      "Road Max Speed (km/h)     0.0045      0.001      3.669      0.000       0.002       0.007\n",
      "AB                        3.7461   2.53e+06   1.48e-06      1.000   -4.96e+06    4.96e+06\n",
      "BC                        3.4939   2.66e+06   1.32e-06      1.000    -5.2e+06     5.2e+06\n",
      "MB                        3.1777   2.48e+06   1.28e-06      1.000   -4.87e+06    4.87e+06\n",
      "NB                        2.6428    2.6e+06   1.02e-06      1.000    -5.1e+06     5.1e+06\n",
      "NL                      -17.7120   2.13e+06  -8.31e-06      1.000   -4.18e+06    4.18e+06\n",
      "NS                        3.3997   2.68e+06   1.27e-06      1.000   -5.25e+06    5.25e+06\n",
      "NT                        5.0169   2.53e+06   1.98e-06      1.000   -4.96e+06    4.96e+06\n",
      "ON                        3.2234   1.87e+06   1.72e-06      1.000   -3.67e+06    3.67e+06\n",
      "QC                        3.3057   1.99e+06   1.66e-06      1.000    -3.9e+06     3.9e+06\n",
      "SK                        2.8705   1.96e+06   1.46e-06      1.000   -3.85e+06    3.85e+06\n",
      "YT                      -17.4678   1.91e+06  -9.15e-06      1.000   -3.74e+06    3.74e+06\n",
      "Active                    0.1063   2.03e+06   5.24e-08      1.000   -3.98e+06    3.98e+06\n",
      "Active - FLB             -1.4499   2.21e+06  -6.57e-07      1.000   -4.33e+06    4.33e+06\n",
      "Active - FLBG            -1.0482   2.38e+06   -4.4e-07      1.000   -4.67e+06    4.67e+06\n",
      "Passive                  -1.9116   2.33e+06  -8.22e-07      1.000   -4.56e+06    4.56e+06\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s = pd.get_dummies(grp['Province'])\n",
    "# s1 = pd.get_dummies(grp['Railway'])\n",
    "s2 = pd.get_dummies(grp['Protection'])\n",
    "# s3 = pd.get_dummies(grp['Location'])\n",
    "# # s4 = pd.get_dummies(grp['SubdOwnerID_DisplayEng'])\n",
    "\n",
    "X = pd.concat([X,s],axis=1)\n",
    "# X = pd.concat([X,s1],axis=1)\n",
    "X = pd.concat([X,s2],axis=1)\n",
    "# X = pd.concat([X,s3],axis=1)\n",
    "# X = pd.concat([X,s4],axis=1)\n",
    "X = sm.add_constant(X)\n",
    "# est= sm.Poisson(y1,X,).fit(cov_type='HC2')\n",
    "# y_pred = est.predict(X)\n",
    "# est.summary()\n",
    "\n",
    "\n",
    "# clf = PoissonRegressor().fit(X,y)\n",
    "poisson_training_results = sm.GLM(y, X, family=sm.families.Poisson()).fit(cov_type='HC2')\n",
    "print(poisson_training_results.summary())\n",
    "y_pred = poisson_training_results.predict(X)\n",
    "\n",
    "# for i in range(1,7):\n",
    "#     sm.graphics.plot_fit(poisson_training_results, i, vlines=False)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# sm.graphics.plot_fit(poisson_training_results, 1, vlines=False)\n",
    "# sm.graphics.plot_fit(poisson_training_results, 2, vlines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10820\\2375171290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregression_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'regression_results' is not defined"
     ]
    }
   ],
   "source": [
    "regression_results(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10820\\859766068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m# regression_results(y_test,y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mregression_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The model score is {pipeline.score(X,y)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regression_results' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn import metrics\n",
    "grp = pd.read_csv('../Data/Group_by.csv',low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "all_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    'Province', \n",
    "    'Protection'\n",
    "]\n",
    "\n",
    "\n",
    "# Cat features of interest\n",
    "categorical_features = [\n",
    "    'Province', \n",
    "    'Protection'\n",
    "    ]\n",
    "# OneHotEncoder to get dummy variables for the cat variables\n",
    "categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#############\n",
    "# Numerical features of intersest\n",
    "numeric_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    ]\n",
    "# Apply a scaler\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    # do the processing on these features of interest and drop the remainders\n",
    "    [\n",
    "        ('categoricals', categorical_transformer, categorical_features),\n",
    "        ('numericals', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "# Creating the pipeline \n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('clf', PoissonRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X = grp[all_features]\n",
    "y = grp['Count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# regression_results(y_test,y_pred)\n",
    "regression_results(y,y_pred)\n",
    "print(f'The model score is {pipeline.score(X,y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10820\\3868052056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# regression_results(y_test,y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mregression_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The model score is {pipeline.score(X,y)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regression_results' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "grp = pd.read_csv('../Data/Group_by.csv',low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "all_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    'Province', \n",
    "    'Protection'\n",
    "]\n",
    "\n",
    "\n",
    "# Cat features of interest\n",
    "categorical_features = [\n",
    "    'Province', \n",
    "    'Protection'\n",
    "    ]\n",
    "# OneHotEncoder to get dummy variables for the cat variables\n",
    "categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#############\n",
    "# Numerical features of intersest\n",
    "numeric_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    ]\n",
    "# Apply a scaler\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    # do the processing on these features of interest and drop the remainders\n",
    "    [\n",
    "        ('categoricals', categorical_transformer, categorical_features),\n",
    "        ('numericals', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "# Creating the pipeline \n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('clf', RandomForestRegressor(criterion='poisson'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X = grp[all_features]\n",
    "y = grp['Count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# regression_results(y_test,y_pred)\n",
    "regression_results(y,y_pred)\n",
    "\n",
    "print(f'The model score is {pipeline.score(X,y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.1081\n",
      "mean_squared_log_error:  0.0916\n",
      "r2:  0.1079\n",
      "MAE:  0.2958\n",
      "MSE:  0.3789\n",
      "RMSE:  0.6155\n",
      "The model score is 0.255001636517889\n"
     ]
    }
   ],
   "source": [
    "grp = pd.read_csv('../Data/Group_by.csv',low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "all_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    'Province', \n",
    "    'Protection'\n",
    "]\n",
    "\n",
    "\n",
    "# Cat features of interest\n",
    "categorical_features = [\n",
    "    'Province', \n",
    "    'Protection'\n",
    "    ]\n",
    "# OneHotEncoder to get dummy variables for the cat variables\n",
    "categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#############\n",
    "# Numerical features of intersest\n",
    "numeric_features = [\n",
    "    'Trains Daily',\n",
    "    'Vehicles Daily',\n",
    "    'Train Max Speed (mph)',\n",
    "    'Road Max Speed (km/h)',\n",
    "    ]\n",
    "# Apply a scaler\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    # do the processing on these features of interest and drop the remainders\n",
    "    [\n",
    "        ('categoricals', categorical_transformer, categorical_features),\n",
    "        ('numericals', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "# Creating the pipeline \n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('clf', HistGradientBoostingRegressor(loss='poisson'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X = grp[all_features]\n",
    "y = grp['Count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "# pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "# y_pred = pipeline.predict(X)\n",
    "\n",
    "regression_results(y_test,y_pred)\n",
    "# regression_results(y,y_pred)\n",
    "\n",
    "print(f'The model score is {pipeline.score(X,y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stoppppp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2260\\2610384745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstoppppp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stoppppp' is not defined"
     ]
    }
   ],
   "source": [
    "stoppppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = pd.read_csv('../Data/Group_by.csv',low_memory=False)\n",
    "y = grp['Count'].astype('float32')\n",
    "X = grp[[\n",
    "                            \n",
    "                            'Trains Daily',\n",
    "                            'Vehicles Daily',\n",
    "                            'Train Max Speed (mph)',\n",
    "                            'Road Max Speed (km/h)',\n",
    "                            # 'ApproxTrainSpeed_MPH',\n",
    "                            # 'NumCars',\n",
    "                            # 'TrainLength_Feet'\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     13279\n",
       "1.0      1402\n",
       "2.0       436\n",
       "3.0       154\n",
       "4.0        54\n",
       "5.0        24\n",
       "6.0        14\n",
       "7.0         3\n",
       "8.0         3\n",
       "10.0        2\n",
       "14.0        1\n",
       "9.0         1\n",
       "17.0        1\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "# y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               500       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,802\n",
      "Trainable params: 6,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        # Input layer\n",
    "        keras.Input(shape=input_shape),\n",
    "        # Hidden layers\\\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.Dense(20, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"relu\"),\n",
    "        # output\n",
    "        layers.Dense(2, activation=\"softmax\"),\n",
    "        # layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cian-work\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 2ms/step - loss: 1.3238 - mse: 0.6731 - val_loss: 0.6332 - val_mse: 0.4398\n",
      "Epoch 2/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6509 - mse: 0.5554 - val_loss: 0.6328 - val_mse: 0.4382\n",
      "Epoch 3/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5549 - val_loss: 0.6327 - val_mse: 0.4380\n",
      "Epoch 4/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5548 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 5/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 6/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 7/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 8/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 9/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 10/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 11/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 12/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 13/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 14/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 15/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 16/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 17/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 18/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 19/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 20/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 21/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 22/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 23/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 24/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 25/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 26/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 27/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 28/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 29/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 30/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 31/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 32/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 33/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 34/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 35/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 36/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 37/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 38/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 39/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 40/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 41/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 42/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 43/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 44/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 45/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 46/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 47/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 48/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 49/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 50/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 51/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 52/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 53/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 54/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 55/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 56/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 57/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 58/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 59/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 60/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 61/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 62/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 63/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 64/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 65/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 66/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 67/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 68/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 69/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 70/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 71/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 72/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 73/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 74/300\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 75/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 76/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 77/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 78/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 79/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 80/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 81/300\n",
      "98/98 [==============================] - 0s 948us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 82/300\n",
      "98/98 [==============================] - 0s 982us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 83/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 84/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 85/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 86/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 87/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 88/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 89/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 90/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 91/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 92/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 93/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 94/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 95/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 96/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 97/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 98/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 99/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 100/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 101/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 102/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 103/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 104/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 105/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 106/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 107/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 108/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 109/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 110/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 111/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 112/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 113/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 114/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 115/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 116/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 117/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 118/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 119/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 120/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 121/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 122/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 123/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 124/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 125/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 126/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 127/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 128/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 129/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 130/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 131/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 132/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 133/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 134/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 135/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 136/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 137/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 138/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 139/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 140/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 141/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 142/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 143/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 144/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 145/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 146/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 147/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 148/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 149/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 150/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 151/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 152/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 153/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 154/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 155/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 156/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 157/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 158/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 159/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 160/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 161/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 162/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 163/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 164/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 165/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 166/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 167/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 168/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 169/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 170/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 171/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 172/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 173/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 174/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 175/300\n",
      "98/98 [==============================] - 0s 975us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 176/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 177/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 178/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 179/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 180/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 181/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 182/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 183/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 184/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 185/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 186/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 187/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 188/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 189/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 190/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 191/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 192/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 193/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 194/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 195/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 196/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 197/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 198/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 199/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 200/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 201/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 202/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 203/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 204/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 205/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 206/300\n",
      "98/98 [==============================] - 0s 983us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 207/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 208/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 209/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 210/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 211/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 212/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 213/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 214/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 215/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 216/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 217/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 218/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 219/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 220/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 221/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 222/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 223/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 224/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 225/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 226/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 227/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 228/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 229/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 230/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 231/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 232/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 233/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 234/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 235/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 236/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 237/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 238/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 239/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 240/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 241/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 242/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 243/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 244/300\n",
      "98/98 [==============================] - 0s 960us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 245/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 246/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 247/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 248/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 249/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 250/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 251/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 252/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 253/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 254/300\n",
      "98/98 [==============================] - 0s 949us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 255/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 256/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 257/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 258/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 259/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 260/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 261/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 262/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 263/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6620 - mse: 0.5557 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 264/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 265/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 266/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 267/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 268/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 269/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 270/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 271/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 272/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 273/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 274/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 275/300\n",
      "98/98 [==============================] - 0s 996us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 276/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 277/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 278/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 279/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 280/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 281/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 282/300\n",
      "98/98 [==============================] - 0s 939us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 283/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 284/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 285/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 286/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 287/300\n",
      "98/98 [==============================] - 0s 991us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 288/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 289/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 290/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 291/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 292/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 293/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 294/300\n",
      "98/98 [==============================] - 0s 970us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 295/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 296/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 297/300\n",
      "98/98 [==============================] - 0s 980us/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 298/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 299/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n",
      "Epoch 300/300\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.5547 - val_loss: 0.6327 - val_mse: 0.4379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "model.compile(loss=\"Poisson\", optimizer=\"adam\", metrics=['mse'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotter(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "\n",
    "  \n",
    "\n",
    "plotter(hist, 'loss')\n",
    "plt.ylim(0,2)\n",
    "plt.show()\n",
    "plotter(hist, 'mse')\n",
    "plt.ylim(0,1.6)\n",
    "plt.show()\n",
    "# plotter(hist, 'mae')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
